# 联邦学习的前沿和开放问题



## 1 引言

联邦学习是一类机器学习，在中心服务器（如：服务提供商）的管理下多个客户端（如：移动设备或整个组织）共同训练一个模型，同时保持训练数据去中心化。联邦学习体现了集中数据收集和最小化的原理，并且可以减轻由传统的集中式机器学习和数据科学方法导致的许多系统隐私风险和成本。受联邦学习研究爆炸性增长的推动，本文讨论了最新进展，并提出了大量未解决的问题和挑战。从研究和应用的角度看，该领域最近都引起了极大的兴趣。本文描述了联邦学习环境的定位和挑战，突出了重要的实践限制和注意事项，然后列举了一系列有价值的研究方向。这项工作的目的是突出具有重大理论和实践意义的研究问题，并鼓励对可能在现实世界中产生重大影响的问题进行研究。

“联邦学习“一词由McMahan等人在2016年提出：“我们将我们的方法称为联邦学习，因为学习任务是由中央服务器协调，通过松散联合的参与设备（我们称为客户端）来解决的”。不平衡且non-IID（非独立同分布）的数据，分布在通信带宽有限的大量不可靠设备中进行分区，这是关键性挑战。

重要的相关工作要早于联邦学习一词的引入。许多研究社区（包括密码学，数据库和机器学习）追求的长期目标是在不暴露数据的情况下分析和学习许多所有者之间分布的数据。用密码学方法计算加密数据始于1980年代初期，Agrawal、Srikant、Vaidya等人是试图使用集中式服务器从本地数据中学习同时保留隐私的早期代表。但是从引入联邦学习一词以来，我们也意识到，没有一项工作能够直接解决联邦学习的全部挑战。因此，术语“联邦学习”为在重要的隐私分散数据引发的机器学习问题中经常出现的一系列特征，约束和挑战提供了方便的简写。

联邦学习许多问题的关键特性是它们本质上是跨学科的，要解决这些问题可能不仅需要机器学习，还需要分布式优化，密码学，安全性，差分隐私，公平性，压缩感知，系统，信息论，统计等等。许多最棘手的问题都在这些领域的交汇处，因此，我们认为合作对于持续发展至关重要。这项工作的目标之一是强调可以将这些领域的技术进行潜在地组合的方式，既带来有趣的可能性，也带来新的挑战。

自从联邦学习一词最初以关注移动和边缘设备应用程序引入以来，将联邦学习应用于其他应用程序的兴趣就大大增加了，包括一些可能只涉及少量相对可靠的客户端的应用程序，例如多个组织合作培训 一个模型。我们将这两个联合学习分别称为“跨设备”和“跨库”。 鉴于这些变化，我们提出了对联合学习的更广泛定义： 

> 联邦学习是一种机器学习设置，其中多个实体（客户端）在中央服务器或服务提供商的协调下协作解决机器学习问题。每个客户的原始数据都存储在本地，不进行交换或转移； 取而代之的是，使用及时聚合的更新来实现学习目标。

重点更新是范围狭窄的更新，其中包含针对特定学习任务所需的最少信息。 在数据最小化服务中，尽可能早地执行聚合。我们注意到，此定义将联邦学习与完全分布式（对等）学习技术区分开来，如2.1节所述。

尽管保护隐私的数据分析已经进行了50多年的研究，但仅在过去的十年中，解决方案才得到大规模部署。跨设备联合学习和联合数据分析现已应用于消费类数字产品。

对联邦学习技术的需求不断增长，导致出现了许多工具和框架。 其中包括TensorFlow Federated，Federated AI Technology Enabler，PySyft，Leaf，PaddleFL和Clara Training Framework； 附录A中有更多详细信息。既有技术公司也有小型初创公司正在开发结合联邦学习的商业数据平台。

表1将跨设备和跨域的联合学习与跨多个域的传统单数据中心分布式学习进行了对比。这些特征建立了实际的联邦学习系统通常必须满足的许多约束，因此可以激发和引出联邦学习中的公开挑战。 它们将在以下各节中详细讨论。

这两个联邦学习变型被称为具有代表性和重要性的案例，但不同的联邦学习环境可能具有这些特征的不同组合。 在本文的其余部分中，除非另有说明，我们将考虑跨设备联邦学习环境，尽管许多问题也适用于其他联邦学习环境。 第2节专门介绍了一些其他联邦学习的变型和应用。

接下来，我们将更详细地考虑跨设备联邦学习，重点关注该技术的典型大规模部署所共有的实践方面。 Bonawitz等人提供了针对特定生产系统的更多细节，包括对特定架构选择和考虑的讨论。

![表1](pictures/Table1.png)

表1：联邦学习环境与数据中心中分布式学习的典型特征（例如[131]）。 跨设备和跨域联邦学习是联邦学习领域的两个示例，但并不旨在穷举。

### 1.1 跨设备联邦学习环境

本节采用了实用的观点，并且与上一节不同，本章并不试图进行定义。相反，目标是描述跨设备联邦学习中的一些实际问题，以及它们如何适合更广泛的机器学习开发和部署生态系统。希望为随后出现的开放性问题提供有用的背景和推动，并帮助研究人员估计在现实世界的系统中部署特定的新方法将有多简单。 我们首先考虑模型的生命周期，然后再考虑联邦学习训练过程。

![](pictures\Figure1.png)

<center>图1：联邦学习训练的模型以及系统中各个参与者的生命周期</center>

#### 1.1.1 联邦学习中模型的生命周期

联邦学习过程通常由模型工程师控制，该工程师为特定应用开发模型。例如，自然语言处理领域专家可以开发用于虚拟键盘的下一单词预测模型。图1显示了主要组件和参与者。 在较高级别上，典型的工作流程是：

1. **问题辨别**：模型工程师判断问题是否要用联邦学习解决。
2. **客户端检测**：如果需要，可以对客户端（例如，在手机上运行的应用）进行检测以在本地存储（时间和数量有限制）必要的训练数据。 在许多情况下，该应用程序已经存储了此数据（例如，短信应用程序必须存储文本消息，照片管理应用程序已存储照片）。 但是，在某些情况下，可能需要维护其他数据或元数据，例如 用户交互数据，为监督学习任务提供标签。
3. **仿真原型（可选）**：模型工程师可以使用代理数据集在联邦学习仿真中对模型体系结构进行原型设计并测试学习超参数。
4. **联邦学习模型训练**：开始执行多个联邦学习训练任务以训练模型的不同变体，或使用不同的优化超参数。
5. **（联邦）模型评估**：在对任务进行了充分的训练（通常是几天，见下文）之后，将对模型进行分析并选择好的候选。 分析的内容可以包括在数据中心中的标准数据集上计算出的度量标准，也可以包括联合评估，其中将模型推送给受约束的客户端，以评估本地客户端数据。
6. **部署**：最后，一旦选择好模型，它将经历一个标准模型启动过程，包括手动质量保证、实时 A/B 测试（通常通过在某些设备上使用新模型和其他设备上的上一代模型来比较其性能），以及分阶段推出（以便在发现较差性能和影响太多用户之前回滚）。模型的特定启动过程由应用程序的所有者设置，通常与模型的训练方法无关。换句话说，此步骤将同样适用于经过联邦学习或传统数据中心方法训练的模型。

![](pictures/Table2.png)

<center>表2：典型的跨设备联合学习应用程序的数量级大小</center>

联邦学习系统面临的主要实际挑战之一是使上述工作流程尽可能简单，理想地接近机器学习系统实现集中训练的易用性。 尽管本文中的大部分内容专门涉及联邦学习训练，但还有许多其他组件，包括联邦学习分析任务，例如模型评估和调试。优化这些问题是3.4节的重点。 现在，我们更详细地考虑单个联邦学习模型的训练（上面的步骤4）。

#### 1.1.2 典型的联邦学习训练过程

现在，我们考虑用于联邦学习训练的模板，该模板包含McMahan等人的联合平均算法，以及其他许多人的研究； 同样，这也可以进行变化，但这提供了一个共同的起点。

服务器（服务提供商）协调训练过程，通过重复以下步骤直到停止训练（由监视培训过程的模型工程师自行决定）：

1. **客户端选择**：服务器从满足资格要求的一组客户端中采样。 例如，移动电话可能仅在连接到未计费的wi-fi且处于空闲状态时才连入服务器，以避免影响设备用户。
2. **广播**：选定的客户端从服务器下载当前模型权重和训练程序（例如 TensorFlow图）。
3. **客户端计算**：每个选定的设备都通过执行训练程序在本地计算对模型的更新，例如，可以在本地数据上运行SGD（例如在联邦平均算法）。
4. **聚合**：服务器收集设备更新的聚合。 为了提高效率，一旦有足够数量的设备报告了结果，就可以放弃那些尚未提交结果的设备。 该阶段也是许多其他技术的集成点，稍后将讨论这些技术，其中可能包括：用于增加隐私的安全聚合，为了通信效率而对聚合进行有损压缩，以及针对差分隐私的噪声添加和更新限幅。
5. **模型更新**：服务器根据从参与当前轮次的客户端计算出的聚合更新，更新在服务器本地的共享模型。

表2给出了移动设备上典型联邦学习应用程序中涉及的数量级大小。

客户端计算、聚合和模型更新阶段的分离并不是联邦学习的严格要求，并且确实排除了某些类的算法（在与其他客户端的聚合之前进行任何更新），例如异步SGD，其中异步的SGD在每个客户端更新之前立即更新模型。这样的异步方法可以简化系统设计的某些方面，并且从优化角度来看也是有益的（尽管这一点尚有争议）。但是，以上介绍的方法在不同研究领域之间的划分方面具有显著优势：压缩，差分隐私和安全的多方计算方面的进步可以针对标准原语开发，例如计算总和或均值而不是分散式更新， 然后由任意优化或分析算法组成，只要这些算法以聚合原语形式表示即可。

还需要强调两个方面，联邦学习训练过程不应影响用户体验。首先，如上所述，尽管通常在每轮联邦学习训练的广播阶段将模型参数发送到某些设备，但这些模型是训练过程的短暂部分，并不用于向用户显示“实时”预测。这是至关重要的，因为训练机器学习模型具有挑战性，而且超参数配置错误会导致做出错误预测的模型。取而代之的是，将用户可见的模型使用推迟到模型生命周期的第6步中详细介绍的部署过程。其次，训练本身对用户是不可见的-如下所述的客户端选择，训练不会减慢设备速度或消耗电池电量，因为训练仅在设备空闲并接通电源时执行。但是，这些限制引入的有限可用性直接导致了开放研究挑战，这些挑战将在随后进行讨论，例如半周期数据可用性以及客户选择中可能存在的偏差。

### 1.2 联邦学习研究

本文的其余部分调查了许多开放问题，这些问题是由现实世界中的联邦学习环境的约束和挑战所激发的，从医院系统的医学数据训练模型到使用数亿移动设备的训练。 不用说，大多数从事联合学习问题的研究人员可能不会部署用于生产的联邦学习系统，也无法访问成千上万的实际设备。 这导致了促进工作的实际环境与模拟中进行的实验之间的关键区别，这些实验提供了给定方法解决激励问题合适的证据。

从实验的角度来看，这使得联邦学习研究与其他机器学习领域有所不同，从而导致进行联邦学习研究时需要考虑其他因素。特别是，在强调未解决的问题时，我们尝试在可能的情况下找出可以在仿真中测量的相关性能指标，数据集的特征（使其更能代表真实的性能）等。对仿真的需求也对联邦学习研究的呈现产生了影响。尽管不打算具有权威性或绝对性，但我们提出以下适度的建议来介绍联邦学习研究，以解决我们描述的未解决问题：

* 如表1所示，联邦学习环境可能包含很多问题。 与确定目标和环境的领域相比，准确描述特定联邦学习环境的细节非常重要，尤其是当所提出的方法做出的假设可能不适用于所有环境时（例如，在各个轮次都参与的有状态客户）。
* 当然，应该提供任何模拟的细节，以使研究可重现。 但是，重要的是要解释一下模拟旨在捕获现实世界环境中的哪些方面（而哪些不是），以便有效地证明在模拟的问题上取得成功意味着在现实世界的目标中取得了有益的进步。 我们希望本文中的指导将对此有所帮助。
* 即使实验是使用公共数据在一台计算机上运行的模拟，但隐私和通信效率始终是FL中的首要问题。 与其他类型的机器学习相比，更重要的是，对于任何建议的方法，必须清楚地知道计算在何处以及所传达的内容。

用于联邦学习模拟的软件库以及标准数据集可以帮助减轻进行有效的联邦学习研究的挑战； 附录A总结了一些当前可用的选项。 针对不同的联邦学习环境（跨设备和跨域）开发标准评估指标并建立标准基准数据集仍然是正在进行的工作的重要方向。

### 1.3 组织

第2节以表1中的思想为基础，探讨了其他联邦学习环境和问题，而最初的重点不在跨设备设置。 然后，第3节将讨论有关提高联邦学习的效率和有效性的核心问题。 第4节仔细考虑了威胁模型，并考虑了一系列技术，以实现严格的隐私保护。 与所有机器学习系统一样，在联邦学习应用程序中，可能会有激励措施来操纵正在训练的模型，并且不可避免地会发生各种故障； 这些挑战将在第5节中讨论。最后，我们将在第6节中讲解提供公平，公正的模型的重要挑战。



## 2 放宽核心联邦学习假设：新兴环境和方案的应用

在本节中，我们将讨论与上一节中讨论的主题相关的研究领域。 尽管不是本文其余部分的主要重点，但在这些领域中取得的进展可能会激发下一代生产系统的设计。

### 2.1 完全分布式/点对点分布式学习

在联邦学习中，中央服务器负责协调训练过程并接收所有客户的贡献。 因此，服务器是中央播放器，它也可能表示单点故障。 尽管大型公司或组织可以在某些应用场景中扮演这个角色，但是在更多协作学习场景中，可能并不总是可以使用或期望可靠而强大的中央服务器。 此外，如Lian等人所述，当客户端数量很大时，服务器甚至可能成为瓶颈。 （尽管可以通过精心的系统设计来减轻这种情况，例如[74]）

完全分散式学习的关键思想，是通过各个客户端之间的对等通信来替换与服务器的通信。通信拓扑表示为连接图，其中节点是客户端，边表示两个客户端之间的通信通道。通常将网络图选择为具有较小最大度的稀疏图，以便每个节点仅需要与少量对等点发送/接收消息。这与服务器-客户端体系结构的星形图相反。在完全分布式的算法中，一轮对应于每个客户端执行本地更新并与图中的其邻居交换信息。在机器学习中，本地更新通常是本地（随机）梯度下降，其通信在于将一个本地模型参数与相邻模型平均。请注意，不再像标准联邦学习中那样存在模型的全局状态，而是可以设计该过程以使所有局部模型都收敛到所需的全局解决方案，即各个模型逐渐达成共识。尽管多主体优化在控制社区中已有悠久的历史，但最近在机器学习中已考虑将SGD的完全分布式变种和其他优化算法用于改善数据中心的可伸缩性[30]和设备的分散网络[110]， 392，379，54，243，253，153]。他们也考虑了无向网络图，尽管有向网络（编码在现实世界中可能会出现的单向通道，例如社交网络或数据市场）的情况也已经在[30，200]中进行了研究。

值得注意的是，即使在上述分布式的环境中，中心机构仍可能负责设置学习任务。 例如，考虑以下问题：谁决定在分散环境下要训练的模型是什么？ 使用什么算法？ 什么超参数？ 当某些东西无法按预期工作时，谁负责调试？要回答这些问题，仍需要中心机构中参与的客户一定程度的信任。 或者，可以由提出学习任务的客户来决定，也可以通过共识来共同做出决定（请参阅第2.1.2节）。

表3比较了联邦学习和点对点学习。 尽管分布式学习的架构假设与联邦式学习的架构假设不同，但分布式学习通常可以应用于类似的问题领域，有许多相同的挑战，并且在研究领域存在大量重叠。因此，我们也在本文中考虑了分散式学习。 在本节中，明确考虑了分布式方法所面临的挑战，但是在分散的情况下，其他部分中的许多未解决问题也会出现。

![](pictures/Table3.png)

表3：联邦学习和完全分布式学习之间主要区别的比较。 请注意，与联邦学习一样，分布式学习可以进一步划分为不同的用例，其区别类似于表1中比较跨域联邦学习和跨设备联邦学习的区别。

#### 2.1.1 算法挑战

关于机器学习的分布式方案在现实世界中的可用性，仍然存在大量重要的算法问题。 有些问题类似于使用中心服务器进行联邦学习的特殊情况，而其他挑战则来自完全分散或缺乏信任的附加副作用。 我们在下面概述了一些特定领域。

**网络拓扑和异步分布式SGD的影响** 完全分布式的学习算法面对客户端的有限的可用性（客户端暂时不可用，在执行过程中退出或加入）应该具有鲁棒性，并且网络的可靠性有限（可能存在消息丢失）。  虽然对于广义线性模型的特殊情况，使用对偶结构的方案可以实现其中一些所需的鲁棒性[201]，但对于深度学习和SGD而言，这仍然是一个悬而未决的问题。当网络图完成但消息具有固定的概率被丢弃时，Yu等人[427]表明，人们可以达到与可靠网络情况相当的收敛速度。其他开放式研究问题涉及non-IID数据分布，更新频率，有效的通信模式和实际收敛时间[379]，我们将在下面更详细地概述。

连接良好或密集的网络可以促进更快的共识，并提供更好的错误收敛速度（取决于网络图的频谱间隙），但它们会导致通信延迟，该延迟随节点度而增加。大多数优化理论的工作都没有明确考虑拓扑如何影响运行时间，即完成每个SGD迭代所需的实际时间。Wang等人[401]提出了MATCHA，一种基于匹配分解采样的分布式SGD方法，它在保持相同的错误收敛速度的同时，减少了任何给定节点拓扑的每次迭代的通信延迟。关键思想是将图拓扑分解为可并行运行的不相交通信链路组成的匹配，并在每次迭代中仔细选择这些匹配的子集。此子图序列导致通过连通性关键链接进行更频繁的通信（确保快速错误收敛），而在其他链接上进行较不频繁的通信（节省通信延迟）。

分布式SGD的设置自然也适合异步算法，其中每个客户端在随机时间独立活动，从而消除了对全局同步的需求并潜在地提高了可伸缩性[110、392、54、30、267]。

与小型批处理SGD中使用单个SGD步骤的方案相比，在通信回合之前执行几个本地更新步骤的方案的理论分析更具挑战性。尽管将在第3.2节中对此进行讨论，但在此处完全分散的环境中也同样适用。 在non-IID本地数据集的情况下，通常证明依赖单个本地更新步骤的方案可以收敛[243，242]。 Wang和Joshi [399]最近提供了具有几个本地更新步骤的案例的收敛性分析。 此外，[401]针对非IID数据情况，但是针对基于上述匹配分解采样的特定方案，提供了收敛分析。 但是，总的来说，了解non-IID数据分布下的收敛以及如何设计实现最快收敛的模型平均策略仍然是一个悬而未决的问题。