## 1 引言

联邦学习是一类机器学习，在中心服务器（如：服务提供商）的管理下多个客户端（如：移动设备或整个组织）共同训练一个模型，同时保持训练数据去中心化。联邦学习体现了集中数据收集和最小化的原理，并且可以减轻由传统的集中式机器学习和数据科学方法导致的许多系统隐私风险和成本。

不平衡且non-IID（非独立同分布）的数据，分布在通信带宽有限的大量不可靠设备中进行分区，这是关键性挑战。

联邦学习许多问题的关键特性是它们本质上是跨学科的，要解决这些问题可能不仅需要机器学习，还需要分布式优化，密码学，安全性，差分隐私，公平性，压缩感知，系统，信息论，统计等等。

![表1](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Table1.png)

表1：联邦学习环境与数据中心中分布式学习的典型特征

### 1.1 跨设备联邦学习环境

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Figure1.png)

<center>图1：联邦学习训练的模型以及系统中各个参与者的生命周期</center>

#### 1.1.1 联邦学习中模型的生命周期

1. **问题辨别**：模型工程师判断问题是否要用联邦学习解决。
2. **客户端检测**：如果需要，可以对客户端（例如，在手机上运行的应用）进行检测以在本地存储（时间和数量有限制）必要的训练数据。 在许多情况下，该应用程序已经存储了此数据（例如，短信应用程序必须存储文本消息，照片管理应用程序已存储照片）。 但是，在某些情况下，可能需要维护其他数据或元数据，例如 用户交互数据，为监督学习任务提供标签。
3. **仿真原型（可选）**：模型工程师可以使用代理数据集在联邦学习仿真中对模型体系结构进行原型设计并测试学习超参数。
4. **联邦学习模型训练**：开始执行多个联邦学习训练任务以训练模型的不同变体，或使用不同的优化超参数。
5. **（联邦）模型评估**：在对任务进行了充分的训练（通常是几天，见下文）之后，将对模型进行分析并选择好的候选。 分析的内容可以包括在数据中心中的标准数据集上计算出的度量标准，也可以包括联合评估，其中将模型推送给受约束的客户端，以评估本地客户端数据。
6. **部署**：最后，一旦选择好模型，它将经历一个标准模型启动过程，包括手动质量保证、实时 A/B 测试（通常通过在某些设备上使用新模型和其他设备上的上一代模型来比较其性能），以及分阶段推出（以便在发现较差性能和影响太多用户之前回滚）。模型的特定启动过程由应用程序的所有者设置，通常与模型的训练方法无关。换句话说，此步骤将同样适用于经过联邦学习或传统数据中心方法训练的模型。

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Table2.png)

<center>表2：典型的跨设备联合学习应用程序的数量级大小</center>

联邦学习系统面临的主要实际挑战之一是使上述工作流程尽可能简单，理想地接近机器学习系统实现集中训练的易用性。

#### 1.1.2 典型的联邦学习训练过程

服务器（服务提供商）协调训练过程，通过重复以下步骤直到停止训练（由监视培训过程的模型工程师自行决定）：

1. **客户端选择**：服务器从满足资格要求的一组客户端中采样。 例如，移动电话可能仅在连接到未计费的wi-fi且处于空闲状态时才连入服务器，以避免影响设备用户。
2. **广播**：选定的客户端从服务器下载当前模型权重和训练程序。
3. **客户端计算**：每个选定的设备都通过执行训练程序在本地计算对模型的更新，例如，可以在本地数据上运行SGD（例如在联邦平均算法）。
4. **聚合**：服务器收集设备更新的聚合。 为了提高效率，一旦有足够数量的设备报告了结果，就可以放弃那些尚未提交结果的设备。 该阶段也是许多其他技术的集成点，稍后将讨论这些技术，其中可能包括：用于增加隐私的安全聚合，为了通信效率而对聚合进行有损压缩，以及针对差分隐私的噪声添加和更新限幅。
5. **模型更新**：服务器根据从参与当前轮次的客户端计算出的聚合更新，更新在服务器本地的共享模型。

## 2 放宽核心联邦学习假设：新兴环境和方案的应用

### 2.1 完全分布式/点对点分布式学习

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Table3.png)

#### 2.1.1 算法挑战

网络拓扑和异步对分散SGD的影响

本地更新分布式SGD

个性化和信任机制

梯度压缩和量化方法

#### 2.1.2 实际挑战

安全聚合协议	

客户端差分隐私

### 2.2 跨域联邦学习

现实情境：如果许多公司或组织共享激励以基于其所有数据来训练模型，但不能直接共享其数据。

```
             +--------------------+
             | Federated Learning |
             +---------+----------+
                       |
          +------------+------------+
          v                         v
+---------+------------+   +--------+-----------+
| Fully Decentralized  |   | Cross-Silo         |
| / Peer-to-Peer       |   | Federated Learning |
| Distributed Learning |   +---------+----------+
| (Cross-Devices)      |             |
+----------------------+   +---------+----------+
                           v                    v
                    +------+-------+    +-------+------+
                    | partitioning |    | partitioning |
                    | by examples  |    | by features  |
                    +--------------+    +--------------+

```

**横向联邦学习**

在两个数据集的用户特征重叠较多而用户重叠较少的情况下，我们把数据集按照横向 (即用户维度)切分，并取出双方用户特征相同而用户不完全相同的那部分数据进行训练。这 种方法叫做横向联邦学习。比如有两家不同地区银行，它们的用户群体分别来自各自所在的地区，相互的交集很小。

**纵向联邦学习**

在两个数据集的用户重叠较多而用户特征重叠较少的情况下，我们把数据集按照纵向 （即特征维度）切分，并取出双方用户相同而用户特征不完全相同的那部分数据进行训练。 这种方法叫做纵向联邦学习。比如有两个不同机构，一家是某地的银行，另一家是同一个地方的电商。它们的用户群体很有可能包含该地的大部分居民，因此用户的交集较大。

**联邦迁移学习**

在两个数据集的用户与用户特征重叠都较少的情况下，我们不对数据进行切分，而可以 利用迁移学习来克服数据或标签不足的情况。这种方法叫做联邦迁移学习。 比如有两个不同机构，一家是位于中国的银行，另一家是位于美国的电商。由于受到地域限制，这两家机构的用户群体交集很小。同时，由于机构类型的不同，二者的数据特征也只有小部分重合。在这种情况下，要想进行有效的联邦学习，就必须引入迁移学习， 来解决单边数据规模小和标签样本少的问题，从而提升模型的效果。

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Figure1-1600307760708.png)

### 2.3 拆分学习

在客户端和服务器之间按层划分模型的执行

每个客户端计算通过深层网络到达特定层（称为切入层）的前向通过。

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Figure2.png)

https://splitlearning.github.io/.

## 3 提高效率和有效性

开发更好的优化算法； 为不同的客户提供不同的模型； 在FL上下文中使诸如超参数搜索，架构搜索和调试之类的ML任务更容易； 提高沟通效率； 和更多。

### 3.1 Non-IID Data in Federated Learning

1.不相同的客户分布

- 特征分布不平衡

- 标签分布不平衡

- 标签不同，特征相同

- 特征不同，标签相同

- 数量偏分布不平衡

non-IID数据集的大多数工作都集中在标签分布不平衡上。

2.数据不独立

3.数据集移位

#### 3.1.1 Strategies for Dealing with Non-IID Data

一种自然的方法是修改现有算法（例如，通过选择不同的超参数）

对于某些应用程序，可能有可能扩充数据，以使跨客户端的数据更加相似。

不再清楚地将所有示例均等地对待是有意义的。 替代方法包括限制来自任何一个用户的数据贡献。

除了解决不相同的客户分布之外，使用多种模型还可以解决由于客户可用性变化而引起的对独立性的损害。

### 3.2 Optimization Algorithms for Federated Learning

在典型的联合学习任务中，目标是要学习一个单一的全局模型，该模型可以使整个训练数据集上的经验风险函数最小化，以实现优化，non-IID和不平衡数据，有限的通信带宽以及不可靠和有限的设备可用性尤其重要。
设备总数巨大的联邦学习环境（例如，跨移动设备）需要每轮只需要几个客户端参与的算法（客户端采样）。 此外，每个设备可能最多只参与一次给定模型的训练，因此无状态算法是必需的。 这排除了直接在数据中心环境中非常有效的各种方法的直接应用。
与其他技术的可组合性。例如密码安全聚合协议，差分隐私以及模型和更新压缩。

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Table4.png)

联合平均算法，适用于本地更新或并行SGD。

### 3.4 Adapting ML Workflows for Federated Learning

#### 3.4.1 Hyperparameter Tuning

在机器学习中超参数调整主要涉及如何提高模型的准确性，而不是针对移动设备的通信和计算效率。 

#### 3.4.2 Neural Architecture Design

神经体系结构搜索（NAS）NAS有三种主要方法，它们利用进化算法，强化学习或梯度下降来搜索特定数据集上特定任务的最佳体系结构。

#### 3.4.3 Debugging and Interpretability for FL

对于一个联邦学习模型，训练是在本地进行的，如果模型出现问题，查找问题的根源将极为困难

### 3.5 Communication and Compression

**Compression objectives**

- 梯度压缩 – 减小了从客户端到服务器通信的对象的大小，该对象用于更新全局模型
- 模型广播压缩– 减小从服务器向客户端广播的模型的大小，客户端从该模型开始本地训练。
- 缩减本地计算 – 对整体训练算法的任何修改，以使本地训练过程在计算上更加有效。

**Compatibility with differential privacy and secure aggregation**

安全聚合和添加噪声以实现差异隐私的机制



参与方可以交换其模型输出参数（logit）而不是模型参数（梯度和/权重），并使用适当的通信和计算资源来优化参与方的调度策略。

## 4 Preserving the Privacy of User Data

我们提倡一种策略，其中整个系统由可以相对独立地研究和改进的模块化单元组成 。

### 4.1 Actors, Threat Models, and Privacy in Depth

Secure Multi-Party Computation (MPC) protocol 安全多方计算

Trusted Execution Environment (TEE) 可信执行平台

Private Disclosure techniques 隐私披露技术

remote attestation and zero-knowledge proofs 远程证明和零知识证明

### 4.2 Tools and Technologies

![](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\Table7.png)

#### 4.2.1 Secure Computations

![image-20200907090416666](D:\study\GitHub\Federated-Learning-Notes\Advances and Open Problems in Federated Learning\联邦学习概述.assets\image-20200907090416666.png)

**Secure computation problems of interest**

*Secure aggregation* 安全聚合

*Secure shuffling* 安全混合

*Private information retrieval* 隐私信息恢复

最新结果表明，通过使用基于格密码系统，可大大降低计算成本

#### 4.2.2 Privacy-Preserving Disclosures

**Local differential privacy**

**Distributed differential privacy**

**Hybrid differential privacy**

#### 4.2.3 Verifiability

多种技术可用于提供可验证性：零知识证明（ZKP），可信执行环境（TEE）或远程证明。

指的是证明者能够在不向验证者提供任何有用的信息的情况下，使验证者相信某个论断是正确的。

### 4.3 Protections Against External Malicious Actors

#### 4.3.1 审核迭代过程和最终模型

#### 4.3.2 集中差异隐私训练

#### 4.3.3 隐藏迭代过程

#### 4.3.4 对不断发展的数据进行重复分析

#### 4.3.5 防止模型盗用和滥用

### 4.4 Protections Against an Adversarial Server

#### 4.4.1 Challenges: Communication Channels, Sybil Attacks, and Selection

在跨设备联邦学习环境中，我们拥有一台具有大量计算资源的服务器和大量客户端，这些客户端（i）仅能与该服务器通信（如星型网络拓扑），并且（ii）连通性可能受到限制和带宽。
控制服务器的主动恶意攻击者可能会模拟大量伪造的客户端设备（“ Sybil攻击”  ），或者可以从可用设备池中优先选择以前受到破坏的设备。

#### 4.4.2 现有解决方案的局限性

**Local differential privacy**

LDP假定用户的隐私完全来自该用户自己的随机性； 因此，用户的隐私保证独立于所有其他用户添加的其他随机性。
造成这种困难的部分原因是，引入的随机噪声的幅度必须与数据中信号的幅度相当，这可能需要合并客户端之间的报告。
因此，要获得与中心差分隐私相同的效果，就需要相对较大的用户群或较大的参数选择。

**Hybrid differential privacy**

它不提供用户本地噪声的隐私放大功能。
目前尚不清楚哪个应用程序领域和算法可以最有效地利用混合信任模型数据，目前在混合模型上的工作通常假设无论用户信任偏好如何，其数据都来自相同的分布

**The shuffle model**

首先是可信中间层的要求

第二个缺点是，The shuffle model的差分隐私保证与参与计算的对手用户数量成比例地降低

**Secure aggregation**

这种方法有几个局限性：（a）假设一个半诚实的服务器（仅在私钥基础结构阶段），（b）允许服务器查看所有的聚合数据（可能仍会泄漏信息），（c  ）对于稀疏向量聚合而言效率不高，并且（d）缺乏强制客户输入格式正确的能力。

#### 



